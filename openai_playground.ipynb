{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test out OpenAI's Large Language Model (LLM) API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "key = os.environ.get('OPENAI_API_KEY')\n",
    "openai.api_key = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Paris\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "    engine=\"text-davinci-002\",\n",
    "    prompt=\"What is the capital of France?\",\n",
    "    max_tokens=1024,\n",
    "    n=1,\n",
    "    stop=None,\n",
    "    temperature=0.5,\n",
    ")\n",
    "\n",
    "generated_text = response[\"choices\"][0][\"text\"]\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-73Z2QF7gPXyztdivs4bDqY0LdLkdA at 0x1f2564d3470> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\nParis\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1681084026,\n",
       "  \"id\": \"cmpl-73Z2QF7gPXyztdivs4bDqY0LdLkdA\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 3,\n",
       "    \"prompt_tokens\": 27,\n",
       "    \"total_tokens\": 30\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Paris\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "    engine=\"text-davinci-002\",\n",
    "    prompt=\"What is the capital of France? Respond with only the capital. If the provided place has no captial, reply with 'None'\",\n",
    "    max_tokens=1024,\n",
    "    n=1,\n",
    "    stop=None,\n",
    "    temperature=0.5,\n",
    ")\n",
    "\n",
    "generated_text = response[\"choices\"][0][\"text\"]\n",
    "print(generated_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test out OpenAI's Whisper API - Voice to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FindyBot5000-assets is a separate private github repo. Feel free to add your own assets by modifying the string below.\n",
    "audio_file= open(r\"..\\FindyBot5000-assets\\audio\\test_inputs\\FindyBot5000 test audio.mp3\", \"rb\")\n",
    "transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text Hello world, this is a test for a FindyBot 5000.\n"
     ]
    }
   ],
   "source": [
    "for k,v in transcript.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world, this is a test for a FindyBot 5000.\n"
     ]
    }
   ],
   "source": [
    "spoken_request = transcript['text']\n",
    "print(spoken_request)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Whisper + LLM. <br>\n",
    "A spoken command will be along the lines of:<br>\n",
    "\"Hey FindyBot, I'm looking for red leds, can you give me a hand?\"\n",
    "1. Whisper will be used to parse Text from Audio\n",
    "2. text-davinci LLM will be used to extract the relevant item from the query, in this case 'red led'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_searched_item(audio_path: str) -> tuple[str, str]:\n",
    "\n",
    "    # Whisper\n",
    "    leds_audio_file= open(audio_path, \"rb\")\n",
    "    leds_transcript = openai.Audio.transcribe(\"whisper-1\", leds_audio_file)\n",
    "    leds_text = leds_transcript['text']\n",
    "\n",
    "    # text-davinci LLM\n",
    "    leds_response = openai.Completion.create(\n",
    "        engine=\"text-davinci-002\",\n",
    "        prompt=f\"Extract the item I am looking for from the following text. Respond with only the item. Make any plural words or acronyms in the response singular. Here is the text: '{leds_text}'\",\n",
    "        max_tokens=1024,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.5,\n",
    "    )\n",
    "\n",
    "    leds_generated_text = leds_response[\"choices\"][0][\"text\"]\n",
    "    return leds_text, leds_generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey Findy Bot, I'm looking for my red LEDs. Can you give me a hand? \n",
      "\n",
      "red LEDs\n"
     ]
    }
   ],
   "source": [
    "text, item = return_searched_item(r\"..\\FindyBot5000-assets\\audio\\test_inputs\\red leds2.mp3\")\n",
    "print(text, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey, FinyBot, where are my AAA batteries? \n",
      "\n",
      "AAA batteries\n"
     ]
    }
   ],
   "source": [
    "text, item = return_searched_item(r\"..\\FindyBot5000-assets\\audio\\test_inputs\\AAA batteries.mp3\")\n",
    "print(text, item)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print speech components using PocketSphinx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a test this is a test on pockets thanks\n",
      "just one two three\n",
      "foreign people\n",
      "find the ball\n",
      "they do\n",
      "what\n",
      "good\n",
      "are you a beer\n",
      "\n",
      "this is this from afar\n",
      "\n",
      "well done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pocketsphinx import LiveSpeech\n",
    "for phrase in LiveSpeech(): print(phrase)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a screenshot of speech recognition with Sphinx. It leaves a little something to be desired...<br>\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('jarvis', -837, 3, 80)]\n",
      "[('jarvis', -369, 4, 87)]\n"
     ]
    }
   ],
   "source": [
    "# Lets see how well keywords can be detected.\n",
    "from pocketsphinx import LiveSpeech\n",
    "\n",
    "speech = LiveSpeech(lm=False, keyphrase='jarvis', kws_threshold=1e-20)\n",
    "for phrase in speech:\n",
    "    print(phrase.segments(detailed=True))\n",
    "\n",
    "# Jarvis won by a long shot over Aura, Lumen, Aria, Lyra, Zara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "say something!…\n",
      "Sphinx thinks you said: 'hey jervis where are my red annuities'\n",
      "Whisper thinks you said: 'Hey Jarvis, where are my red LEDs?'\n",
      "say something!…\n",
      "Sphinx thinks you said: 'the jurors were my trip away batteries'\n",
      "say something!…\n",
      "Sphinx thinks you said: 'he jervis where are my triple a. batteries'\n",
      "Whisper thinks you said: 'Hey Jarvis, where are my AAA batteries?'\n",
      "say something!…\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39m# First try recognize speech using Sphinx, and search the string for any of the keywords\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m# If a keyword is found, pass the raw audio to Whisper to perform full text recognition\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m     recognized_text \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39;49mrecognize_sphinx(audio)\n\u001b[0;32m     21\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSphinx thinks you said: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m recognized_text \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(keyword \u001b[39min\u001b[39;00m recognized_text\u001b[39m.\u001b[39mlower() \u001b[39mfor\u001b[39;00m keyword \u001b[39min\u001b[39;00m keywords):\n",
      "File \u001b[1;32mc:\\Users\\Dustin\\miniconda3\\envs\\FindyBot5000\\Lib\\site-packages\\speech_recognition\\__init__.py:664\u001b[0m, in \u001b[0;36mRecognizer.recognize_sphinx\u001b[1;34m(self, audio_data, language, keyword_entries, grammar, show_all)\u001b[0m\n\u001b[0;32m    662\u001b[0m decoder\u001b[39m.\u001b[39mstart_utt()  \u001b[39m# begin utterance processing\u001b[39;00m\n\u001b[0;32m    663\u001b[0m decoder\u001b[39m.\u001b[39mprocess_raw(raw_data, \u001b[39mFalse\u001b[39;00m, \u001b[39mTrue\u001b[39;00m)  \u001b[39m# process audio data with recognition enabled (no_search = False), as a full utterance (full_utt = True)\u001b[39;00m\n\u001b[1;32m--> 664\u001b[0m decoder\u001b[39m.\u001b[39;49mend_utt()  \u001b[39m# stop utterance processing\u001b[39;00m\n\u001b[0;32m    666\u001b[0m \u001b[39mif\u001b[39;00m show_all: \u001b[39mreturn\u001b[39;00m decoder\n\u001b[0;32m    668\u001b[0m \u001b[39m# return results\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "# Sphinx has some trouble getting 'jarvis' every time...\n",
    "keywords = ['jarvis', 'jervis']\n",
    "\n",
    "r = sr.Recognizer()\n",
    "speech = sr.Microphone(device_index=0)\n",
    "\n",
    "while True:\n",
    "    # Listen for a sentence\n",
    "    with speech as source:\n",
    "        print(\"say something!…\")\n",
    "        audio = r.adjust_for_ambient_noise(source)\n",
    "        audio = r.listen(source)\n",
    "    \n",
    "    # First try recognize speech using Sphinx, and search the string for any of the keywords\n",
    "    # If a keyword is found, pass the raw audio to Whisper to perform full text recognition\n",
    "    try:\n",
    "        recognized_text = r.recognize_sphinx(audio)\n",
    "        \n",
    "        print(\"Sphinx thinks you said: '\" + recognized_text + \"'\")\n",
    "\n",
    "        if any(keyword in recognized_text.lower() for keyword in keywords):\n",
    "            whisper_text = r.recognize_whisper_api(audio, model=\"whisper-1\", api_key=key)\n",
    "            print(\"Whisper thinks you said: '\" + whisper_text + \"'\")\n",
    "\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Sphinx could not understand audio\")  \n",
    "    except sr.RequestError as e:  \n",
    "        print(\"Sphinx error; {0}\".format(e))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic end to end example:\n",
    "1. Listen for a spoken sentence\n",
    "2. Use Sphinx to determine if the keyword was present\n",
    "3. If so, use Whisper for speech-to-text\n",
    "4. Use text-davinci to extract the item that the user is looking for\n",
    "5. Next up... Synthesize voice from response text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "# Sphinx has some trouble getting 'jarvis' every time...\n",
    "keywords = ['jarvis', 'jervis']\n",
    "\n",
    "r = sr.Recognizer()\n",
    "speech = sr.Microphone(device_index=0)\n",
    "\n",
    "while True:\n",
    "    # Listen for a sentence\n",
    "    with speech as source:\n",
    "        print(\"Listening for a sentence...\")\n",
    "        audio = r.adjust_for_ambient_noise(source)\n",
    "        audio = r.listen(source)\n",
    "    \n",
    "    # First try recognize speech using Sphinx, and search the string for any of the keywords\n",
    "    # If a keyword is found, pass the raw audio to Whisper to perform full text recognition\n",
    "    try:\n",
    "        recognized_text = r.recognize_sphinx(audio)\n",
    "        \n",
    "        print(f\"Sphinx thinks you said: '{recognized_text}'\")\n",
    "\n",
    "        # If a keyword wasn't found, go back to listening for input\n",
    "        if not any(keyword in recognized_text.lower() for keyword in keywords):\n",
    "            continue\n",
    "\n",
    "        whisper_text = r.recognize_whisper_api(audio, model=\"whisper-1\", api_key=key)\n",
    "        print(f\"Whisper thinks you said: '{whisper_text}'\")\n",
    "        \n",
    "        # text-davinci LLM\n",
    "        openai_response = openai.Completion.create(\n",
    "            engine=\"text-davinci-002\",\n",
    "            prompt=f\"Extract the item I am looking for from the following text. Respond with only the item. Make any plural words or acronyms in the response singular. Here is the text: '{whisper_text}'\",\n",
    "            max_tokens=1024,\n",
    "            n=1,\n",
    "            stop=None,\n",
    "            temperature=0.5,\n",
    "        )\n",
    "\n",
    "        generated_text = openai_response[\"choices\"][0][\"text\"]\n",
    "\n",
    "        print(f\"OpenAI thinks you are looking for: '{generated_text}'\")\n",
    "\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Sphinx could not understand audio\")  \n",
    "    except sr.RequestError as e:  \n",
    "        print(\"Sphinx error; {0}\".format(e))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FindyBot5000",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
