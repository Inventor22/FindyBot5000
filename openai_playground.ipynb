{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test out OpenAI's Large Language Model (LLM) API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "key = os.environ.get('OPENAI_API_KEY')\n",
    "openai.api_key = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Paris\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "    engine=\"text-davinci-002\",\n",
    "    prompt=\"What is the capital of France?\",\n",
    "    max_tokens=1024,\n",
    "    n=1,\n",
    "    stop=None,\n",
    "    temperature=0.5,\n",
    ")\n",
    "\n",
    "generated_text = response[\"choices\"][0][\"text\"]\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-73Z2QF7gPXyztdivs4bDqY0LdLkdA at 0x1f2564d3470> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\nParis\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1681084026,\n",
       "  \"id\": \"cmpl-73Z2QF7gPXyztdivs4bDqY0LdLkdA\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 3,\n",
       "    \"prompt_tokens\": 27,\n",
       "    \"total_tokens\": 30\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Paris\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "    engine=\"text-davinci-002\",\n",
    "    prompt=\"What is the capital of France? Respond with only the capital. If the provided place has no captial, reply with 'None'\",\n",
    "    max_tokens=1024,\n",
    "    n=1,\n",
    "    stop=None,\n",
    "    temperature=0.5,\n",
    ")\n",
    "\n",
    "generated_text = response[\"choices\"][0][\"text\"]\n",
    "print(generated_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test out OpenAI's Whisper API - Voice to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FindyBot5000-assets is a separate private github repo. Feel free to add your own assets by modifying the string below.\n",
    "audio_file= open(r\"..\\FindyBot5000-assets\\audio\\test_inputs\\FindyBot5000 test audio.mp3\", \"rb\")\n",
    "transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text Hello world, this is a test for a FindyBot 5000.\n"
     ]
    }
   ],
   "source": [
    "for k,v in transcript.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world, this is a test for a FindyBot 5000.\n"
     ]
    }
   ],
   "source": [
    "spoken_request = transcript['text']\n",
    "print(spoken_request)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Whisper + LLM. <br>\n",
    "A spoken command will be along the lines of:<br>\n",
    "\"Hey FindyBot, I'm looking for red leds, can you give me a hand?\"\n",
    "1. Whisper will be used to parse Text from Audio\n",
    "2. text-davinci LLM will be used to extract the relevant item from the query, in this case 'red led'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_searched_item(audio_path: str) -> tuple[str, str]:\n",
    "\n",
    "    # Whisper\n",
    "    leds_audio_file= open(audio_path, \"rb\")\n",
    "    leds_transcript = openai.Audio.transcribe(\"whisper-1\", leds_audio_file)\n",
    "    leds_text = leds_transcript['text']\n",
    "\n",
    "    # text-davinci LLM\n",
    "    leds_response = openai.Completion.create(\n",
    "        engine=\"text-davinci-002\",\n",
    "        prompt=f\"Extract the item I am looking for from the following text. Respond with only the item. Make any plural words or acronyms in the response singular. Here is the text: '{leds_text}'\",\n",
    "        max_tokens=1024,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.5,\n",
    "    )\n",
    "\n",
    "    leds_generated_text = leds_response[\"choices\"][0][\"text\"]\n",
    "    return leds_text, leds_generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey Findy Bot, I'm looking for my red LEDs. Can you give me a hand? \n",
      "\n",
      "red LEDs\n"
     ]
    }
   ],
   "source": [
    "text, item = return_searched_item(r\"..\\FindyBot5000-assets\\audio\\test_inputs\\red leds2.mp3\")\n",
    "print(text, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey, FinyBot, where are my AAA batteries? \n",
      "\n",
      "AAA batteries\n"
     ]
    }
   ],
   "source": [
    "text, item = return_searched_item(r\"..\\FindyBot5000-assets\\audio\\test_inputs\\AAA batteries.mp3\")\n",
    "print(text, item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FindyBot5000",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
